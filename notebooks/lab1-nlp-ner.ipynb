{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:43:17.551896Z",
     "iopub.status.busy": "2025-03-21T07:43:17.551625Z",
     "iopub.status.idle": "2025-03-21T07:43:21.703476Z",
     "shell.execute_reply": "2025-03-21T07:43:21.702578Z",
     "shell.execute_reply.started": "2025-03-21T07:43:17.551874Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install wandb evaluate seqeval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:43:26.767511Z",
     "iopub.status.busy": "2025-03-21T07:43:26.767195Z",
     "iopub.status.idle": "2025-03-21T07:43:26.771762Z",
     "shell.execute_reply": "2025-03-21T07:43:26.770893Z",
     "shell.execute_reply.started": "2025-03-21T07:43:26.767482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, List, Any, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchmetrics.classification import F1Score\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoConfig,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "from spacy import displacy\n",
    "\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add secret for wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:43:27.650461Z",
     "iopub.status.busy": "2025-03-21T07:43:27.650123Z",
     "iopub.status.idle": "2025-03-21T07:43:35.789349Z",
     "shell.execute_reply": "2025-03-21T07:43:35.788621Z",
     "shell.execute_reply.started": "2025-03-21T07:43:27.650434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "user_secrets = UserSecretsClient()\n",
    "my_secret = user_secrets.get_secret(\"wandb_secret\") \n",
    "wandb.login(key=my_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:50:45.553108Z",
     "iopub.status.busy": "2025-03-21T07:50:45.552811Z",
     "iopub.status.idle": "2025-03-21T07:50:46.422318Z",
     "shell.execute_reply": "2025-03-21T07:50:46.421556Z",
     "shell.execute_reply.started": "2025-03-21T07:50:45.553087Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.442930e+05</td>\n",
       "      <td>144293.000000</td>\n",
       "      <td>144293.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.618936e+12</td>\n",
       "      <td>959.818855</td>\n",
       "      <td>1200.791203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.491895e+09</td>\n",
       "      <td>921.054471</td>\n",
       "      <td>1010.457306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.614351e+12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.616884e+12</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>422.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.618862e+12</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>927.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.621222e+12</td>\n",
       "      <td>1404.000000</td>\n",
       "      <td>1696.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.623614e+12</td>\n",
       "      <td>7510.000000</td>\n",
       "      <td>7947.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       discourse_id  discourse_start  discourse_end\n",
       "count  1.442930e+05    144293.000000  144293.000000\n",
       "mean   1.618936e+12       959.818855    1200.791203\n",
       "std    2.491895e+09       921.054471    1010.457306\n",
       "min    1.614351e+12         0.000000       3.000000\n",
       "25%    1.616884e+12       277.000000     422.000000\n",
       "50%    1.618862e+12       685.000000     927.000000\n",
       "75%    1.621222e+12      1404.000000    1696.000000\n",
       "max    1.623614e+12      7510.000000    7947.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/feedback-prize-2021/train.csv\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check bad characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:43:37.529738Z",
     "iopub.status.busy": "2025-03-21T07:43:37.529405Z",
     "iopub.status.idle": "2025-03-21T07:45:58.821552Z",
     "shell.execute_reply": "2025-03-21T07:45:58.820688Z",
     "shell.execute_reply.started": "2025-03-21T07:43:37.529713Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete. Successfully fixed: 15594, Failed: 0\n"
     ]
    }
   ],
   "source": [
    "def fix_mixed_encoding(input_path, output_path):\n",
    "    try:\n",
    "        try:\n",
    "            with open(input_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                \n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "            return True\n",
    "            \n",
    "        except UnicodeDecodeError:\n",
    "            with open(input_path, 'rb') as f:\n",
    "                byte_content = f.read()\n",
    "            \n",
    "            try:\n",
    "                decoded_content = byte_content.decode('cp1252')\n",
    "                with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(decoded_content)\n",
    "                return True\n",
    "                \n",
    "            except UnicodeDecodeError:\n",
    "                fixed_content = bytearray()\n",
    "                i = 0\n",
    "                while i < len(byte_content):\n",
    "                    for j in range(4, 0, -1):  # Try 4, 3, 2, 1 bytes\n",
    "                        if i + j <= len(byte_content):\n",
    "                            try:\n",
    "                                chunk = byte_content[i:i+j].decode('utf-8')\n",
    "                                fixed_content.extend(byte_content[i:i+j])\n",
    "                                i += j\n",
    "                                break\n",
    "                            except UnicodeDecodeError:\n",
    "                                continue\n",
    "                    else:\n",
    "                        try:\n",
    "                            chunk = byte_content[i:i+1].decode('cp1252')\n",
    "                            fixed_content.extend(chunk.encode('utf-8'))\n",
    "                        except UnicodeDecodeError:\n",
    "                            fixed_content.append(byte_content[i])\n",
    "                        i += 1\n",
    "                \n",
    "                with open(output_path, 'wb') as f:\n",
    "                    f.write(fixed_content)\n",
    "                return True\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def process_directory(source_dir, destination_dir):\n",
    "    success_count = 0\n",
    "    failure_count = 0\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "    \n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            source_file_path = os.path.join(root, file)\n",
    "            \n",
    "            relative_path = os.path.relpath(source_file_path, source_dir)\n",
    "            destination_file_path = os.path.join(destination_dir, relative_path)\n",
    "            os.makedirs(os.path.dirname(destination_file_path), exist_ok=True)\n",
    "            \n",
    "            if fix_mixed_encoding(source_file_path, destination_file_path):\n",
    "                success_count += 1\n",
    "            else:\n",
    "                failure_count += 1\n",
    "    \n",
    "    print(f\"\\nProcessing complete. Successfully fixed: {success_count}, Failed: {failure_count}\")\n",
    "\n",
    "# Example usage (commented out)\n",
    "# source_directory = \"/kaggle/input/feedback-prize-2021/train\"\n",
    "# destination_directory = \"/kaggle/working/feedback-prize-2021/train\"\n",
    "# process_directory(source_directory, destination_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cluster into grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:51:11.415098Z",
     "iopub.status.busy": "2025-03-21T07:51:11.414803Z",
     "iopub.status.idle": "2025-03-21T07:51:11.786900Z",
     "shell.execute_reply": "2025-03-21T07:51:11.786155Z",
     "shell.execute_reply.started": "2025-03-21T07:51:11.415077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_cluster = pd.read_csv(\"/kaggle/input/feedback-clustering/essays_with_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:51:16.241767Z",
     "iopub.status.busy": "2025-03-21T07:51:16.241437Z",
     "iopub.status.idle": "2025-03-21T07:51:16.287949Z",
     "shell.execute_reply": "2025-03-21T07:51:16.287073Z",
     "shell.execute_reply.started": "2025-03-21T07:51:16.241738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_cluster['id'] = df_cluster['file_name'].str.replace('.txt', '', regex=False)\n",
    "df = df.merge(df_cluster[['id', 'predicted_grade_cluster']], on='id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:45:59.703114Z",
     "iopub.status.busy": "2025-03-21T07:45:59.702816Z",
     "iopub.status.idle": "2025-03-21T07:45:59.722792Z",
     "shell.execute_reply": "2025-03-21T07:45:59.721992Z",
     "shell.execute_reply.started": "2025-03-21T07:45:59.703086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_tag(anns):\n",
    "    discourse_types = anns['discourse_type'].unique()\n",
    "    tag_map = {'O': 0}\n",
    "    tag_idx = 1\n",
    "    for discourse_type in discourse_types:\n",
    "        tag_map[f'B-{discourse_type}'] = tag_idx\n",
    "        tag_idx += 1\n",
    "        tag_map[f'I-{discourse_type}'] = tag_idx\n",
    "        tag_idx += 1\n",
    "    return tag_map\n",
    "\n",
    "\n",
    "class DataProcessor():\n",
    "    def __init__(self, text_dir, anns, tokenizer, tag_map, max_length=2048, include_cluster=True):\n",
    "        self.text_dir = text_dir\n",
    "        self.anns = anns\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.include_cluster = include_cluster\n",
    "        self.file_ids = self.anns['id'].unique()\n",
    "        self.discourse_types = self.anns['discourse_type'].unique()\n",
    "        self.tag_map = tag_map\n",
    "            \n",
    "        if self.include_cluster:\n",
    "            self.cluster_tokens = [f\"[CLUSTER_{i}]\" for i in range(6)]\n",
    "            special_tokens = {\"additional_special_tokens\": self.cluster_tokens}\n",
    "            self.tokenizer.add_special_tokens(special_tokens)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.file_ids)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        file_id = self.file_ids[idx]\n",
    "        \n",
    "        with open(os.path.join(self.text_dir, f\"{file_id}.txt\"), 'r', encoding='utf-8') as f:\n",
    "            text = f.read().strip()\n",
    "        text = text.replace(\"\\n\\n\", \" \\n\\n\")\n",
    "        \n",
    "        file_annotations = self.anns[self.anns['id'] == file_id]\n",
    "        words = text.split(\" \")\n",
    "        \n",
    "        word_labels = ['O'] * len(words)\n",
    "        \n",
    "        for _, row in file_annotations.iterrows():\n",
    "            discourse_type = row['discourse_type']\n",
    "            word_indices = [int(idx) for idx in str(row['predictionstring']).split()]\n",
    "            \n",
    "            for i, word_idx in enumerate(word_indices):\n",
    "                if word_idx < len(word_labels):\n",
    "                    word_labels[word_idx] = f'B-{discourse_type}' if i == 0 else f'I-{discourse_type}'\n",
    "        \n",
    "        cluster_token_word = None\n",
    "        if self.include_cluster and not file_annotations.empty:\n",
    "            cluster = file_annotations['predicted_grade_cluster'].iloc[0]\n",
    "            cluster_token_word = self.cluster_tokens[int(cluster)]\n",
    "        \n",
    "        if cluster_token_word:\n",
    "            tokenizer_input = [cluster_token_word] + words\n",
    "        else:\n",
    "            tokenizer_input = words\n",
    "        \n",
    "        encodings = self.tokenizer(\n",
    "            tokenizer_input,\n",
    "            is_split_into_words=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        word_ids = encodings.word_ids(batch_index=0)\n",
    "        \n",
    "        token_labels = []\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                # Special tokens like [CLS], [SEP], [PAD]\n",
    "                token_labels.append(-100)\n",
    "            elif self.include_cluster and cluster_token_word and word_id == 0:\n",
    "                # cluster token\n",
    "                token_labels.append(-100)\n",
    "            else:\n",
    "                adjusted_word_id = word_id - 1 if (self.include_cluster and cluster_token_word) else word_id\n",
    "                if adjusted_word_id < len(word_labels):\n",
    "                    token_labels.append(self.tag_map[word_labels[adjusted_word_id]])\n",
    "                else:\n",
    "                    token_labels.append(self.tag_map['O'])\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encodings.input_ids[0],\n",
    "            'attention_mask': encodings.attention_mask[0],\n",
    "            'labels': torch.tensor(token_labels),\n",
    "            'word_ids' : word_ids,\n",
    "            'file_id': file_id,\n",
    "            \"words\" : words\n",
    "        }\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:45:59.723715Z",
     "iopub.status.busy": "2025-03-21T07:45:59.723495Z",
     "iopub.status.idle": "2025-03-21T07:45:59.739106Z",
     "shell.execute_reply": "2025-03-21T07:45:59.738515Z",
     "shell.execute_reply.started": "2025-03-21T07:45:59.723689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class NERDataCollator:\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizerBase, max_length: int = 2048):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids = [feature['input_ids'] for feature in features]\n",
    "        attention_mask = [feature['attention_mask'] for feature in features]\n",
    "        labels = [feature['labels'] for feature in features]\n",
    "        file_ids = [feature['file_id'] for feature in features]\n",
    "        words = [feature['words'] for feature in features]\n",
    "        word_ids = [feature['word_ids'] for feature in features]\n",
    "        \n",
    "        input_ids = [ids.tolist() if isinstance(ids, torch.Tensor) else ids for ids in input_ids]\n",
    "        attention_mask = [mask.tolist() if isinstance(mask, torch.Tensor) else mask for mask in attention_mask]\n",
    "        labels = [lbl.tolist() if isinstance(lbl, torch.Tensor) else lbl for lbl in labels]\n",
    "        \n",
    "        batch_max_length = min(max(len(ids) for ids in input_ids), self.max_length)\n",
    "        padded_input_ids = []\n",
    "        padded_attention_mask = []\n",
    "        padded_labels = []\n",
    "        pad_token_id = self.tokenizer.pad_token_id if self.tokenizer.pad_token_id is not None else 0\n",
    "        \n",
    "        for ids, mask, lbl in zip(input_ids, attention_mask, labels):\n",
    "            padding_length = batch_max_length - len(ids)\n",
    "            padded_input_ids.append(ids + [pad_token_id] * padding_length)\n",
    "            padded_attention_mask.append(mask + [0] * padding_length)\n",
    "            padded_labels.append(lbl + [-100] * padding_length)\n",
    "        \n",
    "        batch = {\n",
    "            \"input_ids\": torch.tensor(padded_input_ids, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(padded_attention_mask, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(padded_labels, dtype=torch.long),\n",
    "            \"file_ids\": file_ids,\n",
    "            \"words\": words,\n",
    "            \"word_ids\": word_ids\n",
    "        }\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:45:59.741300Z",
     "iopub.status.busy": "2025-03-21T07:45:59.741070Z",
     "iopub.status.idle": "2025-03-21T07:45:59.758913Z",
     "shell.execute_reply": "2025-03-21T07:45:59.758306Z",
     "shell.execute_reply.started": "2025-03-21T07:45:59.741281Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_predictions_to_predictionstring(file_id, word_ids, words, predicted_labels, tag_map):\n",
    "    idx_to_tag = {v: k for k, v in tag_map.items()}\n",
    "    \n",
    "    # Check for cluster token\n",
    "    has_cluster_token = False\n",
    "    if len(words) > 0 and isinstance(words[0], str) and words[0].startswith('[CLUSTER_'):\n",
    "        has_cluster_token = True\n",
    "    \n",
    "    # Track word-level predictions\n",
    "    final_word_predictions = {}\n",
    "    for token_idx, (word_idx, pred_label) in enumerate(zip(word_ids, predicted_labels)):\n",
    "        pred_label = int(pred_label)\n",
    "        if word_idx is None or pred_label == -100:\n",
    "            continue\n",
    "        \n",
    "        if has_cluster_token and word_idx == 0:\n",
    "            continue\n",
    "            \n",
    "        adjusted_word_idx = word_idx - 1 if has_cluster_token else word_idx\n",
    "            \n",
    "        if adjusted_word_idx < len(words):\n",
    "            if pred_label in idx_to_tag:\n",
    "                tag = idx_to_tag[pred_label]\n",
    "                # Only include non-O tags in final predictions\n",
    "                if tag != 'O':\n",
    "                    final_word_predictions[adjusted_word_idx] = tag\n",
    "    \n",
    "    discourse_spans = []\n",
    "    current_type = None\n",
    "    current_indices = []\n",
    "    \n",
    "    all_word_indices = set(range(len(words)))\n",
    "    if has_cluster_token:\n",
    "        all_word_indices = set(range(len(words) - 1))  # cluster token\n",
    "    \n",
    "    for i in sorted(all_word_indices):\n",
    "        if i in final_word_predictions:\n",
    "            tag = final_word_predictions[i]\n",
    "            \n",
    "            if tag.startswith('B-') or (current_type is None and tag.startswith('I-')):\n",
    "                if current_type and current_indices:\n",
    "                    discourse_spans.append({\n",
    "                        'discourse_type': current_type,\n",
    "                        'predictionstring': ' '.join(map(str, current_indices))\n",
    "                    })\n",
    "                \n",
    "                \n",
    "                current_type = tag[2:]  # Remove B- and I-\n",
    "                current_indices = [i]\n",
    "                \n",
    "            elif tag.startswith('I-') and current_type == tag[2:]:\n",
    "                if current_indices and i == current_indices[-1] + 1:\n",
    "                    current_indices.append(i)\n",
    "                else:\n",
    "                    if current_type and current_indices:\n",
    "                        discourse_spans.append({\n",
    "                            'discourse_type': current_type,\n",
    "                            'predictionstring': ' '.join(map(str, current_indices))\n",
    "                        })\n",
    "                    current_type = tag[2:]\n",
    "                    current_indices = [i]\n",
    "        else:\n",
    "            if current_type and current_indices:\n",
    "                discourse_spans.append({\n",
    "                    'discourse_type': current_type,\n",
    "                    'predictionstring': ' '.join(map(str, current_indices))\n",
    "                })\n",
    "                current_type = None\n",
    "                current_indices = []\n",
    "    \n",
    "    if current_type and current_indices:\n",
    "        discourse_spans.append({\n",
    "            'discourse_type': current_type,\n",
    "            'predictionstring': ' '.join(map(str, current_indices))\n",
    "        })\n",
    "    \n",
    "    for span in discourse_spans:\n",
    "        span['id'] = file_id\n",
    "    \n",
    "    return discourse_spans\n",
    "\n",
    "def merge_consecutive_spans(spans_list):\n",
    "    if not spans_list:\n",
    "        return pd.DataFrame(columns=['id', 'discourse_type', 'predictionstring'])\n",
    "    \n",
    "    processed_spans = []\n",
    "    for span in spans_list:\n",
    "        new_span = span.copy()\n",
    "        new_span['indices'] = set(map(int, span['predictionstring'].split()))\n",
    "        processed_spans.append(new_span)\n",
    "    \n",
    "    processed_spans.sort(key=lambda x: min(x['indices']))\n",
    "    \n",
    "    merged_spans = []\n",
    "    current_span = None\n",
    "    \n",
    "    for span in processed_spans:\n",
    "        if current_span is None:\n",
    "            current_span = span\n",
    "        elif (span['discourse_type'] == current_span['discourse_type'] and \n",
    "              span['id'] == current_span['id'] and\n",
    "              any(idx == max(current_span['indices']) + 1 for idx in span['indices'])):\n",
    "            current_span['indices'].update(span['indices'])\n",
    "        else:\n",
    "            indices_list = sorted(current_span['indices'])\n",
    "            current_span['predictionstring'] = ' '.join(map(str, indices_list))\n",
    "            del current_span['indices']\n",
    "            merged_spans.append(current_span)\n",
    "            current_span = span\n",
    "    \n",
    "    if current_span:\n",
    "        indices_list = sorted(current_span['indices'])\n",
    "        current_span['predictionstring'] = ' '.join(map(str, indices_list))\n",
    "        del current_span['indices']\n",
    "        merged_spans.append(current_span)\n",
    "    \n",
    "    df = pd.DataFrame(merged_spans)\n",
    "    \n",
    "    if not df.empty:\n",
    "        df = df[['id', 'discourse_type', 'predictionstring']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T08:30:34.998875Z",
     "iopub.status.busy": "2025-03-21T08:30:34.998579Z",
     "iopub.status.idle": "2025-03-21T08:30:35.017544Z",
     "shell.execute_reply": "2025-03-21T08:30:35.016706Z",
     "shell.execute_reply.started": "2025-03-21T08:30:34.998854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TokenClassificationModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name_or_path: str,\n",
    "        tokenizer,\n",
    "        num_labels: int = 15,\n",
    "        learning_rate: float = 2e-5,\n",
    "        weight_decay: float = 0.01,\n",
    "        warmup_steps: int = 500,\n",
    "        total_steps: Optional[int] = None,\n",
    "        freeze_layers: int = 0,\n",
    "        id2label=None,\n",
    "        label_names=None,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.save_hyperparameters(ignore=[\"tokenizer\"])\n",
    "        \n",
    "        config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "        config.num_labels = num_labels\n",
    "\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            config=config,\n",
    "        )\n",
    "        if tokenizer is not None:\n",
    "            self.model.resize_token_embeddings(len(tokenizer))\n",
    "        \n",
    "        self.train_f1 = F1Score(task=\"multiclass\", num_classes=num_labels, ignore_index=-100)\n",
    "        self.val_f1 = F1Score(task=\"multiclass\", num_classes=num_labels, ignore_index=-100)\n",
    "        \n",
    "        self.seqeval_metric = evaluate.load(\"seqeval\")\n",
    "        self.id2label = id2label\n",
    "        self.label_names = label_names\n",
    "        \n",
    "        self.val_predictions = []\n",
    "        self.val_labels = []\n",
    "        \n",
    "        self.validation_step_outputs = []\n",
    "        \n",
    "    def forward(self, **inputs):\n",
    "        return self.model(**inputs)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self.model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=batch[\"labels\"]\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        self.train_f1(preds, batch[\"labels\"])\n",
    "        \n",
    "        self.log(\"train_loss\", loss, on_step=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self.model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=batch[\"labels\"]\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        self.val_f1(preds, batch[\"labels\"])\n",
    "        \n",
    "        self.val_predictions.extend(preds.detach().cpu().tolist())\n",
    "        self.val_labels.extend(batch[\"labels\"].detach().cpu().tolist())\n",
    "        \n",
    "        self.log(\"val_loss_step\", loss, on_step=True, prog_bar=True)\n",
    "        \n",
    "        self.validation_step_outputs.append(loss.detach())\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        train_f1 = self.train_f1.compute()\n",
    "        self.log(\"train_f1\", train_f1, on_epoch=True, prog_bar=True)\n",
    "        self.train_f1.reset()\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_val_loss = torch.stack(self.validation_step_outputs).mean()\n",
    "        self.log(\"val_loss\", avg_val_loss, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.validation_step_outputs.clear()\n",
    "        \n",
    "        # Standard F1 metric\n",
    "        val_f1 = self.val_f1.compute()\n",
    "        self.log(\"val_f1\", val_f1, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.val_f1.reset()\n",
    "        \n",
    "        if self.id2label is not None:\n",
    "            metrics = self.compute_seqeval_metrics(self.val_predictions, self.val_labels)\n",
    "            self.log(\"val_seqeval_precision\", metrics[\"precision\"], on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "            self.log(\"val_seqeval_recall\", metrics[\"recall\"], on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "            self.log(\"val_seqeval_f1\", metrics[\"f1\"], on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "            self.log(\"val_seqeval_accuracy\", metrics[\"accuracy\"], on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        \n",
    "        self.val_predictions = []\n",
    "        self.val_labels = []\n",
    "    \n",
    "    def compute_seqeval_metrics(self, predictions, labels):\n",
    "        true_labels = [[self.id2label[l] for l in label if l != -100] for label in labels]\n",
    "        true_predictions = [\n",
    "            [self.id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "        all_metrics = self.seqeval_metric.compute(predictions=true_predictions, references=true_labels)\n",
    "        return {\n",
    "            \"precision\": all_metrics[\"overall_precision\"],\n",
    "            \"recall\": all_metrics[\"overall_recall\"],\n",
    "            \"f1\": all_metrics[\"overall_f1\"],\n",
    "            \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "        }\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        outputs = self.model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"]\n",
    "        )\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        return {\n",
    "            \"logits\": logits,\n",
    "            \"predictions\": predictions,\n",
    "            \"essay_id\": batch.get(\"essay_id\", None),\n",
    "            \"words\": batch.get(\"words\", None),\n",
    "            \"word_labels\": batch.get(\"word_labels\", None)\n",
    "        }\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparams.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(\n",
    "            optimizer_grouped_parameters, \n",
    "            lr=self.hparams.learning_rate\n",
    "        )\n",
    "        \n",
    "        if self.hparams.total_steps is None:\n",
    "            return optimizer\n",
    "        \n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.hparams.warmup_steps,\n",
    "            num_training_steps=self.hparams.total_steps,\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### refine output with beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:46:46.591874Z",
     "iopub.status.busy": "2025-03-21T07:46:46.591499Z",
     "iopub.status.idle": "2025-03-21T07:46:46.597078Z",
     "shell.execute_reply": "2025-03-21T07:46:46.595980Z",
     "shell.execute_reply.started": "2025-03-21T07:46:46.591838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def beam_search(logits, beam_size = 5):\n",
    "    preds = []\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "    # take top-k labels for each token\n",
    "    topk_probs, topk_indices = torch.topk(\n",
    "        probs, beam_size, dim=-1\n",
    "    )  # shape: (batch_size, seq_len, beam_width)\n",
    "\n",
    "    # choose the most probable sequence from beam search\n",
    "    best_seq = topk_indices[:, :, 0].cpu().numpy()\n",
    "\n",
    "    preds.extend(best_seq)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train/Val in KFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T10:34:56.742905Z",
     "iopub.status.busy": "2025-03-21T10:34:56.742567Z",
     "iopub.status.idle": "2025-03-21T10:34:56.766332Z",
     "shell.execute_reply": "2025-03-21T10:34:56.765581Z",
     "shell.execute_reply.started": "2025-03-21T10:34:56.742876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_with_folds_lightning(\n",
    "    data_processor,\n",
    "    model_class,\n",
    "    model_name_or_path,\n",
    "    anns,\n",
    "    data_collator,\n",
    "    id2label,\n",
    "    n_splits=5, \n",
    "    batch_size=8,\n",
    "    num_workers=4,\n",
    "    max_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    project_name=\"token-classification\",\n",
    "    entity_name=\"vvilgurin-igor-sikorsky-kyiv-polytechnic-institute\",\n",
    "    experiment_name=\"token-classification-cv-1\",\n",
    "    patience=3,\n",
    "    using_clusters=True\n",
    "):\n",
    "\n",
    "    print(\"init wandb\")\n",
    "    wandb.init(\n",
    "        project=project_name,\n",
    "        entity=entity_name,\n",
    "        name=experiment_name,\n",
    "        config={\n",
    "            \"n_splits\": n_splits,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"max_epochs\": max_epochs,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"model_name\": model_name_or_path,\n",
    "            \"using_clusters\": using_clusters\n",
    "        }\n",
    "    )\n",
    "\n",
    "    using_clusters = hasattr(data_processor, 'include_cluster') and data_processor.include_cluster\n",
    "    file_id_to_idx = {file_id: idx for idx, file_id in enumerate(data_processor.file_ids)}\n",
    "    unique_ids = data_processor.file_ids\n",
    "    \n",
    "    print(\"splitting folds\")\n",
    "    if using_clusters:\n",
    "        file_clusters = {}\n",
    "        for file_id in unique_ids:\n",
    "            file_anns = anns[anns['id'] == file_id]\n",
    "            if not file_anns.empty and 'predicted_grade_cluster' in file_anns.columns:\n",
    "                # Handle potential NaN values\n",
    "                cluster_value = file_anns['predicted_grade_cluster'].iloc[0]\n",
    "                if pd.isna(cluster_value):\n",
    "                    file_clusters[file_id] = -1\n",
    "                else:\n",
    "                    file_clusters[file_id] = int(cluster_value)\n",
    "            else:\n",
    "                file_clusters[file_id] = -1\n",
    "                \n",
    "        print(\"grouping clusters\")\n",
    "        cluster_to_files = {}\n",
    "        for file_id, cluster in file_clusters.items():\n",
    "            if cluster not in cluster_to_files:\n",
    "                cluster_to_files[cluster] = []\n",
    "            cluster_to_files[cluster].append(file_id)\n",
    "        \n",
    "        folds = [[] for _ in range(n_splits)]\n",
    "        print(\"filling the clusters\")\n",
    "        for cluster, files in cluster_to_files.items():\n",
    "            import random\n",
    "            random.seed(42) \n",
    "            random.shuffle(files)\n",
    "            \n",
    "            for i, file_id in enumerate(files):\n",
    "                fold_idx = i % n_splits\n",
    "                folds[fold_idx].append(file_id)\n",
    "        \n",
    "        print(\"convert to train/test\")\n",
    "        fold_indices = []\n",
    "        for i in range(n_splits):\n",
    "            val_file_ids = folds[i]\n",
    "            train_file_ids = [fid for j in range(n_splits) if j != i for fid in folds[j]]\n",
    "            \n",
    "            train_indices = [file_id_to_idx[fid] for fid in train_file_ids]\n",
    "            val_indices = [file_id_to_idx[fid] for fid in val_file_ids]\n",
    "            \n",
    "            fold_indices.append((train_indices, val_indices))\n",
    "    else:\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        fold_indices = []\n",
    "        \n",
    "        for train_idx, val_idx in kf.split(range(len(unique_ids))):\n",
    "            fold_indices.append((train_idx.tolist(), val_idx.tolist()))\n",
    "    \n",
    "    all_results = []\n",
    "    best_models = []\n",
    "    \n",
    "    print(\"Training start\")\n",
    "    for fold, (train_indices, val_indices) in enumerate(tqdm(fold_indices, desc=\"Cross-validation folds\")):\n",
    "        fold_name = f\"{experiment_name}_fold_{fold+1}\"\n",
    "        print(f\"Training fold {fold+1}/{n_splits}\")\n",
    "        \n",
    "        train_dataset = Subset(data_processor, train_indices)\n",
    "        val_dataset = Subset(data_processor, val_indices)\n",
    "        \n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=data_collator,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "        \n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=data_collator,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "        \n",
    "        wandb_logger = WandbLogger(\n",
    "            project=project_name,\n",
    "            entity=entity_name,\n",
    "            name=fold_name,\n",
    "            group=experiment_name, \n",
    "            log_model=True\n",
    "        )\n",
    "        \n",
    "        total_steps = len(train_dataloader) * max_epochs\n",
    "        warmup_steps = int(0.1 * total_steps)  \n",
    "        \n",
    "        lightning_model = model_class(\n",
    "            model_name_or_path=model_name_or_path,\n",
    "            num_labels=data_processor.num_labels if hasattr(data_processor, 'num_labels') else 15,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            warmup_steps=warmup_steps,\n",
    "            total_steps=total_steps, \n",
    "            tokenizer=data_processor.tokenizer,\n",
    "            id2label=id2label,\n",
    "            label_names=list(tags.keys())\n",
    "        )\n",
    "        \n",
    "        wandb_logger.log_hyperparams({\n",
    "            \"fold\": fold + 1,\n",
    "            \"train_size\": len(train_dataset),\n",
    "            \"val_size\": len(val_dataset)\n",
    "        })\n",
    "        \n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=f\"checkpoints/{experiment_name}/fold_{fold+1}\",\n",
    "            filename=\"model-{epoch:02d}-{val_f1:.4f}\",\n",
    "            monitor=\"val_f1\",\n",
    "            mode=\"max\",\n",
    "            save_top_k=1,\n",
    "            save_weights_only=False\n",
    "        )\n",
    "        \n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=\"val_f1\",\n",
    "            min_delta=0.001,\n",
    "            patience=patience,\n",
    "            verbose=True,\n",
    "            mode=\"max\"\n",
    "        )\n",
    "        \n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=max_epochs,\n",
    "            devices=1, \n",
    "            accelerator=\"auto\",\n",
    "            logger=wandb_logger,\n",
    "            callbacks=[checkpoint_callback, early_stop_callback],\n",
    "            enable_checkpointing=True,\n",
    "            deterministic=True,\n",
    "            accumulate_grad_batches=8\n",
    "        )\n",
    "        \n",
    "        trainer.fit(\n",
    "            model=lightning_model,\n",
    "            train_dataloaders=train_dataloader,\n",
    "            val_dataloaders=val_dataloader\n",
    "        )\n",
    "        \n",
    "        fold_results = trainer.validate(lightning_model, val_dataloader)\n",
    "        all_results.append(fold_results)\n",
    "        \n",
    "        best_models.append({\n",
    "            \"fold\": fold + 1,\n",
    "            \"val_f1\": fold_results[0][\"val_f1\"],\n",
    "            \"checkpoint_path\": checkpoint_callback.best_model_path\n",
    "        })\n",
    "\n",
    "        print(f\"Fold {fold+1} validation results: {fold_results}\")\n",
    "        \n",
    "        wandb.finish()\n",
    "    \n",
    "    best_model_info = max(best_models, key=lambda x: x[\"val_f1\"])\n",
    "    \n",
    "    val_losses = [result[0][\"val_loss\"] for result in all_results]\n",
    "    val_f1s = [result[0][\"val_f1\"] for result in all_results]\n",
    "    \n",
    "    cv_results = {\n",
    "        \"mean_val_loss\": np.mean(val_losses),\n",
    "        \"std_val_loss\": np.std(val_losses),\n",
    "        \"mean_val_f1\": np.mean(val_f1s),\n",
    "        \"std_val_f1\": np.std(val_f1s),\n",
    "        \"best_model\": best_model_info\n",
    "    }\n",
    "    \n",
    "    wandb.init(\n",
    "        project=project_name,\n",
    "        entity=entity_name,\n",
    "        name=f\"{experiment_name}_cv_summary\",\n",
    "        group=experiment_name\n",
    "    )\n",
    "    \n",
    "    wandb.log({\n",
    "        \"cv_mean_val_loss\": cv_results[\"mean_val_loss\"],\n",
    "        \"cv_std_val_loss\": cv_results[\"std_val_loss\"],\n",
    "        \"cv_mean_val_f1\": cv_results[\"mean_val_f1\"],\n",
    "        \"cv_std_val_f1\": cv_results[\"std_val_f1\"],\n",
    "        \"best_fold\": best_model_info[\"fold\"],\n",
    "        \"best_fold_f1\": best_model_info[\"val_f1\"]\n",
    "    })\n",
    "    \n",
    "    fold_table = wandb.Table(columns=[\"Fold\", \"Validation Loss\", \"Validation F1\"])\n",
    "    for i, result in enumerate(all_results):\n",
    "        fold_table.add_data(i+1, result[0][\"val_loss\"], result[0][\"val_f1\"])\n",
    "    \n",
    "    wandb.log({\"fold_results_table\": fold_table})\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Cross-validation completed with {n_splits} folds\")\n",
    "    print(f\"Mean Validation F1: {cv_results['mean_val_f1']:.4f} ± {cv_results['std_val_f1']:.4f}\")\n",
    "    print(f\"Mean Validation Loss: {cv_results['mean_val_loss']:.4f} ± {cv_results['std_val_loss']:.4f}\")\n",
    "    print(f\"Best model from fold {best_model_info['fold']} with F1: {best_model_info['val_f1']:.4f}\")\n",
    "    print(f\"Best model path: {best_model_info['checkpoint_path']}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return cv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T10:35:00.740588Z",
     "iopub.status.busy": "2025-03-21T10:35:00.740286Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init wandb\n",
      "splitting folds\n",
      "grouping clusters\n",
      "filling the clusters\n",
      "convert to train/test\n",
      "Training start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation folds:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BigBirdForTokenClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "Attention type 'block_sparse' is not possible if sequence_length: 699 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e71e7aea00544318fa4fb6c0319c2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff28813d97f4e61af71793453a0b3ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7864494919776917     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6806506514549255     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    val_loss_step_epoch    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6806517839431763     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   val_seqeval_accuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7864494919776917     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      val_seqeval_f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3225943148136139     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   val_seqeval_precision   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.28021547198295593    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    val_seqeval_recall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.38007569313049316    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7864494919776917    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6806506514549255    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   val_loss_step_epoch   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6806517839431763    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  val_seqeval_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7864494919776917    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     val_seqeval_f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3225943148136139    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  val_seqeval_precision  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.28021547198295593   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   val_seqeval_recall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.38007569313049316   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 validation results: [{'val_loss_step_epoch': 0.6806517839431763, 'val_loss': 0.6806506514549255, 'val_f1': 0.7864494919776917, 'val_seqeval_precision': 0.28021547198295593, 'val_seqeval_recall': 0.38007569313049316, 'val_seqeval_f1': 0.3225943148136139, 'val_seqeval_accuracy': 0.7864494919776917}]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████</td></tr><tr><td>train_f1</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▄▆▄▅▆▄▅▄▄▆▂▅▂▂▂▃▂▅▂▂▂▂▃▂▃▄▅▄▂▂▁▃▃▃▃▃▃▄▃</td></tr><tr><td>trainer/global_step</td><td>█▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▂▅▅▅▆▆▇▇▇▇██▂▂▂▂▂▂▃▃▃▄▄</td></tr><tr><td>val_f1</td><td>▁██</td></tr><tr><td>val_loss</td><td>█▁▁</td></tr><tr><td>val_loss_step_epoch</td><td>█▁▁</td></tr><tr><td>val_loss_step_step</td><td>▃▆▇▆▇▇▅█▆▂▆▄▁▅▄▄▅▅▃▅▄▃▄▄█▆▆▆▅▅▅▅▃▃▂▅▅▅▄▅</td></tr><tr><td>val_seqeval_accuracy</td><td>▁██</td></tr><tr><td>val_seqeval_f1</td><td>▁██</td></tr><tr><td>val_seqeval_precision</td><td>▁██</td></tr><tr><td>val_seqeval_recall</td><td>▁██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>train_f1</td><td>0.77508</td></tr><tr><td>train_loss</td><td>0.44424</td></tr><tr><td>trainer/global_step</td><td>1300</td></tr><tr><td>val_f1</td><td>0.78645</td></tr><tr><td>val_loss</td><td>0.68065</td></tr><tr><td>val_loss_step_epoch</td><td>0.68065</td></tr><tr><td>val_loss_step_step</td><td>0.74082</td></tr><tr><td>val_seqeval_accuracy</td><td>0.78645</td></tr><tr><td>val_seqeval_f1</td><td>0.32259</td></tr><tr><td>val_seqeval_precision</td><td>0.28022</td></tr><tr><td>val_seqeval_recall</td><td>0.38008</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">big-bird-folds-cluster_fold_2</strong> at: <a href='https://wandb.ai/vvilgurin-igor-sikorsky-kyiv-polytechnic-institute/token-classification/runs/yzl3gygk' target=\"_blank\">https://wandb.ai/vvilgurin-igor-sikorsky-kyiv-polytechnic-institute/token-classification/runs/yzl3gygk</a><br> View project at: <a href='https://wandb.ai/vvilgurin-igor-sikorsky-kyiv-polytechnic-institute/token-classification' target=\"_blank\">https://wandb.ai/vvilgurin-igor-sikorsky-kyiv-polytechnic-institute/token-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250321_102206-yzl3gygk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py:2299: UserWarning: Run (yzl3gygk) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "Cross-validation folds:  33%|███▎      | 1/3 [41:57<1:23:55, 2517.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BigBirdForTokenClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250321_111936-gj7uhnak</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vvilgurin-igor-sikorsky-kyiv-polytechnic-institute/token-classification/runs/gj7uhnak' target=\"_blank\">big-bird-folds-cluster_fold_2</a></strong> to <a href='https://wandb.ai/vvilgurin-igor-sikorsky-kyiv-polytechnic-institute/token-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vvilgurin-igor-sikorsky-kyiv-polytechnic-institute/token-classification' target=\"_blank\">https://wandb.ai/vvilgurin-igor-sikorsky-kyiv-polytechnic-institute/token-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vvilgurin-igor-sikorsky-kyiv-polytechnic-institute/token-classification/runs/gj7uhnak' target=\"_blank\">https://wandb.ai/vvilgurin-igor-sikorsky-kyiv-polytechnic-institute/token-classification/runs/gj7uhnak</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 717 to 768 to be a multiple of `config.block_size`: 64\n",
      "Input ids are automatically padded from 779 to 832 to be a multiple of `config.block_size`: 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc556a90f0044b54aab06cf5c2837ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 537 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    }
   ],
   "source": [
    "tags = get_tag(df)\n",
    "id2label = {id: label for label, id in tags.items()}\n",
    "anns = df\n",
    "data_processor = DataProcessor(text_dir, anns, tokenizer, tags)\n",
    "data_collator = NERDataCollator(tokenizer)\n",
    "# anns = pd.read_csv('/kaggle/input/feedback-prize-2021/train.csv')\n",
    "\n",
    "cv_results = train_with_folds_lightning(\n",
    "    data_processor=data_processor,\n",
    "    model_class=TokenClassificationModule,\n",
    "    model_name_or_path=\"google/bigbird-roberta-base\", \n",
    "    anns=anns,\n",
    "    id2label = id2label,\n",
    "    data_collator=data_collator,\n",
    "    n_splits=3,\n",
    "    batch_size=2,\n",
    "    max_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    experiment_name=\"big-bird-folds-cluster\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_model = TokenClassificationModule.load_from_checkpoint(cv_results[\"best_model\"][\"checkpoint_path\"])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2970755,
     "isSourceIdPinned": false,
     "sourceId": 31779,
     "sourceType": "competition"
    },
    {
     "datasetId": 6922759,
     "sourceId": 11105941,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv_nlp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
